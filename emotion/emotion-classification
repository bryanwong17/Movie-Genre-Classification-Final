{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"emotion-classification","provenance":[],"authorship_tag":"ABX9TyPIYV75+iB32bRaJ9VFqIt1"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xe3hqqlOFBm8","executionInfo":{"status":"ok","timestamp":1623363318264,"user_tz":-480,"elapsed":1480,"user":{"displayName":"Michelle Soen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG74W72MpjNnvPlJwsYxmR0Hi0UCbBWyPEhKMH=s64","userId":"03820532445770256937"}},"outputId":"dcf846c1-b0e3-4185-853f-cd065d1cdfc0"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U1ct_fC6GxNX","executionInfo":{"status":"ok","timestamp":1623363321056,"user_tz":-480,"elapsed":2804,"user":{"displayName":"Michelle Soen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG74W72MpjNnvPlJwsYxmR0Hi0UCbBWyPEhKMH=s64","userId":"03820532445770256937"}},"outputId":"16cb2c96-2eb4-45d5-bd00-32ed24498804"},"source":["!pip install face-recognition"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: face-recognition in /usr/local/lib/python3.7/dist-packages (1.3.0)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face-recognition) (7.1.2)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face-recognition) (19.18.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face-recognition) (1.19.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face-recognition) (7.1.2)\n","Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from face-recognition) (0.3.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"aDKal3MtEqAS","executionInfo":{"status":"error","timestamp":1623363322614,"user_tz":-480,"elapsed":1561,"user":{"displayName":"Michelle Soen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG74W72MpjNnvPlJwsYxmR0Hi0UCbBWyPEhKMH=s64","userId":"03820532445770256937"}},"outputId":"1678b275-cf45-4c10-9ec6-5b334d736293"},"source":["import dlib\n","import dlib.cuda as cuda\n","\n","#if cuda.get_num_devices() >= 1 and not dlib.DLIB_USE_CUDA:\n","#  dlib.DLIB_USE_CUDA = True\n","#print(cuda.get_num_devices(), dlib.DLIB_USE_CUDA)\n","dlib.DLIB_USE_CUDA = False\n","\n","import face_recognition\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, Dense, Activation, Dropout, Flatten, BatchNormalization, MaxPool2D\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm"],"execution_count":3,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-c4bc669a4619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDLIB_USE_CUDA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/face_recognition/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1.2.3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_face_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_landmarks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcnn_face_detection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detector_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcnn_face_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detection_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_face_detection_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mface_recognition_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_recognition_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-wheel-mmuzni47/dlib/dlib/cuda/gpu_data.cpp:201. code: 100, reason: no CUDA-capable device is detected"]}]},{"cell_type":"code","metadata":{"id":"uV62ZkZEFN1B","executionInfo":{"status":"aborted","timestamp":1623363322608,"user_tz":-480,"elapsed":9,"user":{"displayName":"Michelle Soen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG74W72MpjNnvPlJwsYxmR0Hi0UCbBWyPEhKMH=s64","userId":"03820532445770256937"}}},"source":["facial_expressions = ['ANGRY', 'DISGUSTED', 'FEARFUL', 'HAPPY', 'SAD', 'SURPRISED', 'NEUTRAL']\n","\n","fe_model = Sequential()\n","        \n","fe_model.add(Conv2D(32, 3, input_shape=(48, 48, 1), padding='same', activation='relu'))\n","fe_model.add(BatchNormalization())\n","fe_model.add(Conv2D(32, 3, padding='same', activation='relu'))\n","fe_model.add(BatchNormalization())\n","fe_model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n","\n","fe_model.add(Conv2D(64, 3, padding='same', activation='relu'))\n","fe_model.add(BatchNormalization())\n","fe_model.add(Conv2D(64, 3, padding='same', activation='relu'))\n","fe_model.add(BatchNormalization())\n","fe_model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n","fe_model.add(Dropout(0.25))\n","\n","fe_model.add(Conv2D(128, 3, padding='same', activation='relu'))\n","fe_model.add(BatchNormalization())\n","fe_model.add(Conv2D(128, 3, padding='same', activation='relu'))\n","fe_model.add(BatchNormalization())\n","fe_model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n","fe_model.add(Dropout(0.25))\n","\n","fe_model.add(Flatten())\n","fe_model.add(Dense(256))\n","fe_model.add(Activation('relu'))\n","fe_model.add(BatchNormalization())\n","fe_model.add(Dropout(0.5))\n","\n","fe_model.add(Dense(256))\n","fe_model.add(Activation('relu'))\n","fe_model.add(BatchNormalization())\n","fe_model.add(Dropout(0.5))\n","\n","fe_model.add(Dense(256))\n","fe_model.add(Activation('relu'))\n","fe_model.add(BatchNormalization())\n","fe_model.add(Dropout(0.5))\n","\n","fe_model.add(Dense(len(facial_expressions)))\n","fe_model.add(Activation('softmax'))\n","\n","fe_model.compile(loss='categorical_crossentropy', \n","                 optimizer='adam', \n","                 metrics=['accuracy']\n","                 )\n","\n","fe_model.load_weights('/content/gdrive/MyDrive/zt-trailer/facial-expression-weights.h5')\n","\n","fe_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXwBchf7GX1u","executionInfo":{"status":"aborted","timestamp":1623363322610,"user_tz":-480,"elapsed":11,"user":{"displayName":"Michelle Soen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG74W72MpjNnvPlJwsYxmR0Hi0UCbBWyPEhKMH=s64","userId":"03820532445770256937"}}},"source":["def detect_expression(gray_img):    \n","    gray_img = cv2.resize(gray_img, (48, 48))\n","    gray_img = np.reshape(gray_img, (1, 48, 48, 1))\n","\n","    res = fe_model.predict(gray_img)\n","    return str(facial_expressions[np.argmax(res[0])])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A3D8zZ1SIa-i","executionInfo":{"status":"aborted","timestamp":1623363322611,"user_tz":-480,"elapsed":11,"user":{"displayName":"Michelle Soen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG74W72MpjNnvPlJwsYxmR0Hi0UCbBWyPEhKMH=s64","userId":"03820532445770256937"}}},"source":["def get_emotion_list(mn):\n","  path = '/content/gdrive/MyDrive/zt-trailer/trailer-dataset/' + mn + '.mp4'\n","  vc = cv2.VideoCapture(path)\n","  if not vc.isOpened():\n","      print(\"get_frames: failed to open video at \" + video_path + \"; operation terminated.\")\n","      return []\n","\n","  emotion_lists = []\n","  frame_idx = 0\n","  while(True):\n","    vc.set(cv2.CAP_PROP_POS_MSEC, 500 * frame_idx)\n","    success, img = vc.read()\n","    if not success:\n","      break\n","    \n","    f_locs = face_recognition.face_locations(img)\n","    emotion_dict = {expr[:3]: 0 for expr in facial_expressions}\n","    emotion_dict['ND'] = 1\n","    for f_loc in f_locs:\n","      t, r, b, l = f_loc\n","      face_img_gray = cv2.cvtColor(img[t:b, l:r], cv2.COLOR_BGR2GRAY)\n","      expr = detect_expression(face_img_gray)\n","      emotion_dict[expr[:3]] += 2\n","\n","    emotion_lists.append(max(emotion_dict, key=emotion_dict.get))\n","    frame_idx += 1\n","\n","  vc.release()\n","  return emotion_lists"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bdzK3O_8HhBa","executionInfo":{"status":"aborted","timestamp":1623363322612,"user_tz":-480,"elapsed":12,"user":{"displayName":"Michelle Soen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG74W72MpjNnvPlJwsYxmR0Hi0UCbBWyPEhKMH=s64","userId":"03820532445770256937"}}},"source":["train_data = pd.read_csv('/content/gdrive/MyDrive/zt-trailer/train_data.csv').drop(\"Unnamed: 0\", axis=1)\n","test_data = pd.read_csv('/content/gdrive/MyDrive/zt-trailer/test_data.csv').drop(\"Unnamed: 0\", axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Fc-QQIqR6hO","executionInfo":{"status":"aborted","timestamp":1623363322612,"user_tz":-480,"elapsed":12,"user":{"displayName":"Michelle Soen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG74W72MpjNnvPlJwsYxmR0Hi0UCbBWyPEhKMH=s64","userId":"03820532445770256937"}}},"source":["# emotion_test_pd = []\n","# for idx, row in (test_data.iterrows()):\n","#   print(row['mo'])\n","#   emotion_test_pd.append(\",\".join(get_emotion_list(row['movie'])))\n","#   pd.DataFrame(emotion_test_pd).to_csv('/content/gdrive/MyDrive/zt-trailer/test_feat.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9eUfpi2KYRT-","executionInfo":{"status":"aborted","timestamp":1623363322613,"user_tz":-480,"elapsed":13,"user":{"displayName":"Michelle Soen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG74W72MpjNnvPlJwsYxmR0Hi0UCbBWyPEhKMH=s64","userId":"03820532445770256937"}}},"source":["emotion_train_pd = []\n","for idx, row in (train_data.iterrows()):\n","  print(idx, row['movie'])\n","  if idx < 66: continue\n","  elif idx == 66:\n","    pass\n","    ## emotion_train_pd.append(\"ERR\")\n","    ## continue\n","  emotion_train_pd.append(\",\".join(get_emotion_list(row['movie'])))\n","  pd.DataFrame(emotion_train_pd).to_csv('/content/gdrive/MyDrive/zt-trailer/train_feat5.csv')"],"execution_count":null,"outputs":[]}]}